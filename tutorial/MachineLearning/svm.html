<!DOCTYPE html>
<html>
<head>
	<title>Ludivine Morvan, Deep learning for survival</title>
	<meta name="description" content="Tutorials on survival analysis, machine learning and deep learning.">
	<meta name="keywords" content="Ludivine Morvan, Deep learning, machine learning, survival analysis, multiple myeloma, Ls2n, CRCINA, Random Survival Forest, RSF, CNN">
	<meta name="author" content="Ludivine Morvan">
	<link rel="stylesheet" type="text/css" href="../../css/main.css">
	<script id="MathJax-script" async
	src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
	<div class="entete">
		<h2>Ludivine Morvan</h2>
	</div>
	<nav>
		<ul>
			<li><a href="../../index.html">Home</a></li>
			<li><a href="../../about.html">About me</a></li>
			<li><a href="../../work.html">Current work</a></li>
			<li><a href="../../cv.html">CV</a></li>
			<li><a href="../../publication.html">Publications</a></li>
			<li><a href="../../tutorial.html">Tutorials</a></li>
		</ul>
	</nav>
	<div class="container">
		<div class="tutoNavig">
			<ul>
				<li><a class='t1' href="../survival/survival.html">Survival</a></li>
				<ul>
					<li><a class='t2' href="../survival/survival.html">Generalities</a></li>
					<li><a class='t2' href="../survival/kaplanM.html">Survival statistical learning</a></li>
					<li><a class='t2' href="../survival/RSF.html">Survival machine learning</a></li>

				</ul>
				<li><a class='t1' href="../MachineLearning/generalities.html">Machine learning</a></li>
				<ul>
					<li><a class='t2' href="../MachineLearning/generalities.html">Generalities</a></li>
					<li><a class='t2act' href="../MachineLearning/reg.html">Supervised learning</a></li>
					<ul>
						<li><a class='t3act' href="../MachineLearning/reg.html">Regression methods</a></li>
						<li><a class='t3' href="../MachineLearning/RF.html">Decision trees methods</a></li>
						<li><a class='t3' href="../MachineLearning/svm.html">SVM</a></li>
						<li><a class='t3' href="../MachineLearning/knn.html">k-nearest neighbors</a></li>
						<li><a class='t3' href="../MachineLearning/nn.html">Neural Networks</a></li>
					</ul>
					<li><a class='t2' href="../MachineLearning/PCA.html">Unsupervised learning</a></li>
					<ul>
						<li><a class='t3' href="../MachineLearning/PCA.html">PCA</a></li>
						<li><a class='t3' href="../MachineLearning/kmeans.html">K-means clustering</a></li>
					</ul>
				</ul>
				<li><a class='t1' href="../DeepLearning/generalities.html">Deep
					learning</a></li>
					<ul>
						<li><a class='t2' href="../DeepLearning/generalities.html">Generalities</a></li>
						<li><a class='t2' href="../DeepLearning/layers.html">Layers</a></li>
						<li><a class='t2' href="../DeepLearning/loss.html">Losses</a></li>
					</ul>
				</ul>
			</div><!-- /.tutoNavig -->
			

			<div class="mainT">
				<div class=arrow>
					<div class=previous>
						<a href= 'RF.html'> <image src=../../previous.png alt='next' title='Decision trees methods' width=12% height=12%/> &nbsp; Previous </a>
					</div> <!-- /.previous -->

					<div class=next>
						<a href= 'knn.html'>Next &nbsp; <image src=../../next.png alt='next'
							title='K-nearest neighbors' width=15% height=15%/> </a>
						</div> <!-- /.next -->
					</div> <!-- /.arrow -->
					<h1>SVM</h1>
					<p>Page in progress ...</p>
					<!-- <p>SVMs have a flexible structure and are regularly found in articles such as the one by Fayçal Ben Bouallègue
					et al.[1]. They allow regression and classification. </p>


					<p>We start from a set
					\({(x_{i},y_{i})}_{i=1,...,n}\) , with  \(x_{i}\) a vector of \(p\) characteristics for individual  \(i\) and  \(y_{i}\) the class of the individual.
					In the two-class classification problem (e.g. good and bad prognosis), the goal is to construct a function that predicts whether our new example
					will belong to class 1 or 2. We then look for a separation surface. That is to say, we must find the function  \(f\) such that  \(f(x)=0\)
					separates the two classes with the least possible error [2].</p>
					<p> More precisely, we are looking for a hyperplane \(h(x)\) which separates the points into 2 classes. The function of \(h(x)\) is defined as follows:
					$$h(x) = W^T X_i + w_0$$ with \(W\) the coefficients of the hyperplane and \(w_0\) the coordinate at the origin. To find the solution, we use the constraints that for all \(i \),
					$$ W^T X_i + w_0 > 0 if y_i = Class 1 $$ and $$ W^T X_i + w_0 > 0 if y_i = Class 2 $$.	 </p>
					<p>However, there may be many solutions to the equation h(x)=0, and the solution is to add a margin on each side of the hyperplane, which must be maximised.</p>




					<div class=biblio id="bibliosvm">
					<h1>References</h1>
					<p>[1] Fayçal Ben Bouallègue et al. Association between textural and morphological tumor indices on baseline PET-CT and early metabolic response on interim PET-CT in bulky malignant lymphomas. Med. Phys., 44: 4608-4619 (2017) </p>
					<p>[2] Marin Ferecatu et Nicolas Thome Michel Crucianu. Cours - svm lineaires. Cours Cnam RCP209 (2010). </p>
				</div>
			-->

		</div><!-- /.mainT -->
	</div><!-- /.container -->

	<div class=arrow>
		<div class=previous>
			<a href= 'RF.html'> <image src=../../previous.png alt='next' title='Decision trees methods' width=12% height=12%/> &nbsp; Previous </a>
		</div> <!-- /.previous -->

		<div class=next>
			<a href= 'knn.html'>Next &nbsp; <image src=../../next.png alt='next'
				title='K-nearest neighbors' width=15% height=15%/> </a>
			</div> <!-- /.next -->
		</div> <!-- /.arrow -->

		<footer>
			<ul>
				<li><a href="mailto:ludivine.morvan@ls2n.fr">email</a></li>

				<!--<li><a href="https://github.com/ludivinemv">github</a></li>-->						<li><a href="https://www.researchgate.net/profile/Ludivine_Morvan">researchgate</a></li>
				<li><a href="https://www.linkedin.com/in/ludivine-morvan-884153151/">linkedin</a></li>
			</ul>
		</footer>
	</body>
	</html>
